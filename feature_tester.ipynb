{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e882a1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path (/Users/rik/Documents/VU/DMT/DataMiningTechniquesA2) already exists in sys.path\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run ./initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4cd098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lgbm_ranker import LGBMRankerModel, LGBMRanker\n",
    "from feature_tester import FeatureTester\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940224a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"data/training_set_processed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674af584",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_class_model = LGBMRankerModel(\n",
    "    df = train_df,              # Only initialized to get column names\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[5],\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da4de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.362862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7548\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.389358\n",
      "[200]\tvalid_0's ndcg@5: 0.395328\n",
      "[300]\tvalid_0's ndcg@5: 0.397886\n",
      "[400]\tvalid_0's ndcg@5: 0.399382\n",
      "[500]\tvalid_0's ndcg@5: 0.400988\n",
      "Early stopping, best iteration is:\n",
      "[497]\tvalid_0's ndcg@5: 0.40125\n",
      "Model trained successfully with the following categorical features threshold: {'srch_destination_id': 1000}\n",
      "Number of categories for srch_destination_id: 899\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.4012500931985614)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.352134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8181\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388299\n",
      "[200]\tvalid_0's ndcg@5: 0.393923\n",
      "[300]\tvalid_0's ndcg@5: 0.397105\n",
      "[400]\tvalid_0's ndcg@5: 0.398465\n",
      "[500]\tvalid_0's ndcg@5: 0.399945\n",
      "Early stopping, best iteration is:\n",
      "[488]\tvalid_0's ndcg@5: 0.400113\n",
      "Model trained successfully with the following categorical features threshold: {'srch_destination_id': 500}\n",
      "Number of categories for srch_destination_id: 1598\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.4001131429688723)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.353665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7048\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.389763\n",
      "[200]\tvalid_0's ndcg@5: 0.396331\n",
      "[300]\tvalid_0's ndcg@5: 0.399133\n",
      "[400]\tvalid_0's ndcg@5: 0.400796\n",
      "Early stopping, best iteration is:\n",
      "[447]\tvalid_0's ndcg@5: 0.401635\n",
      "Model trained successfully with the following categorical features threshold: {'srch_destination_id': 2500}\n",
      "Number of categories for srch_destination_id: 365\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.40163484050126586)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.344287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6844\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388319\n",
      "[200]\tvalid_0's ndcg@5: 0.39518\n",
      "[300]\tvalid_0's ndcg@5: 0.398809\n",
      "[400]\tvalid_0's ndcg@5: 0.400643\n",
      "[500]\tvalid_0's ndcg@5: 0.401616\n",
      "[600]\tvalid_0's ndcg@5: 0.402403\n",
      "Early stopping, best iteration is:\n",
      "[575]\tvalid_0's ndcg@5: 0.402631\n",
      "Model trained successfully with the following categorical features threshold: {'srch_destination_id': 5000}\n",
      "Number of categories for srch_destination_id: 142\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.4026305956916656)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.409216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6692\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388356\n",
      "[200]\tvalid_0's ndcg@5: 0.395364\n",
      "[300]\tvalid_0's ndcg@5: 0.398718\n",
      "[400]\tvalid_0's ndcg@5: 0.40098\n",
      "[500]\tvalid_0's ndcg@5: 0.402221\n",
      "[600]\tvalid_0's ndcg@5: 0.403066\n",
      "[700]\tvalid_0's ndcg@5: 0.403962\n",
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's ndcg@5: 0.404127\n",
      "Model trained successfully with the following categorical features threshold: {'site_id': 5000, 'visitor_location_country_id': 1000, 'prop_country_id': 1000, 'srch_destination_id': 5000}\n",
      "Number of categories for site_id: 27\n",
      "Number of categories for visitor_location_country_id: 78\n",
      "Number of categories for prop_country_id: 94\n",
      "Number of categories for srch_destination_id: 142\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.4041274422834456)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.349070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6729\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.389258\n",
      "[200]\tvalid_0's ndcg@5: 0.395881\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m feature_tester \u001b[38;5;241m=\u001b[39m FeatureTester(lgbm_class_model)\n\u001b[1;32m      2\u001b[0m list_of_categorical_features_threshold \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2500\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5000\u001b[39m}, \n\u001b[1;32m      3\u001b[0m                                           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitor_location_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprop_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5000\u001b[39m}, \n\u001b[1;32m      4\u001b[0m                                           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitor_location_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprop_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5000\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitor_location_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprop_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2500\u001b[39m}]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mfeature_tester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_cardinal_reduction_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_of_categorical_features_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/VU/DMT/DataMiningTechniquesA2/feature_tester.py:25\u001b[0m, in \u001b[0;36mFeatureTester.test_cardinal_reduction_methods\u001b[0;34m(self, list_of_categorical_features_threshold)\u001b[0m\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m     24\u001b[0m X_train, y_train, X_val, y_val, groups_size_train, groups_size_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mformat_data(df)\n\u001b[0;32m---> 25\u001b[0m model_opt \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups_size_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups_size_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel trained successfully with the following categorical features threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategorical_features_threshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m categorical_features_threshold:\n",
      "File \u001b[0;32m~/Documents/VU/DMT/DataMiningTechniquesA2/lgbm_ranker.py:80\u001b[0m, in \u001b[0;36mLGBMRankerModel.fit\u001b[0;34m(self, X_train, y_train, X_val, y_val, groups_size_train, groups_size_val, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m fitted_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups_size_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# counts per srch_id\u001b[39;49;00m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mgroups_size_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fitted_model\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:1780\u001b[0m, in \u001b[0;36mLGBMRanker.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, eval_at, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1775\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould set group for all eval datasets for ranking task; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1776\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif you use dict, the index should start from 0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1777\u001b[0m         )\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_at \u001b[38;5;241m=\u001b[39m eval_at\n\u001b[0;32m-> 1780\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    311\u001b[0m     cb(\n\u001b[1;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4154\u001b[0m _safe_call(\n\u001b[0;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4159\u001b[0m )\n\u001b[1;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_tester = FeatureTester(lgbm_class_model)\n",
    "list_of_categorical_features_threshold = [{\"srch_destination_id\": 1000}, {\"srch_destination_id\": 500}, {\"srch_destination_id\": 2500}, {\"srch_destination_id\": 5000}, \n",
    "                                          {\"site_id\": 5000, \"visitor_location_country_id\": 1000, \"prop_country_id\": 1000, \"srch_destination_id\": 5000}, \n",
    "                                          {\"site_id\": 2500, \"visitor_location_country_id\": 500, \"prop_country_id\": 500, \"srch_destination_id\": 5000}, {\"site_id\": 2500, \"visitor_location_country_id\": 500, \"prop_country_id\": 500, \"srch_destination_id\": 2500}]\n",
    "feature_tester.test_cardinal_reduction_methods(list_of_categorical_features_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b36a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.379983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6689\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.38862\n",
      "[200]\tvalid_0's ndcg@5: 0.395762\n",
      "[300]\tvalid_0's ndcg@5: 0.399033\n",
      "[400]\tvalid_0's ndcg@5: 0.40119\n",
      "[500]\tvalid_0's ndcg@5: 0.402302\n",
      "[600]\tvalid_0's ndcg@5: 0.403876\n",
      "[700]\tvalid_0's ndcg@5: 0.404278\n",
      "[800]\tvalid_0's ndcg@5: 0.404723\n",
      "Early stopping, best iteration is:\n",
      "[795]\tvalid_0's ndcg@5: 0.404954\n",
      "Model trained successfully with imputing the null values for columns: {'prop_review_score': 'median', 'orig_destination_distance': 'mean'}\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.404954094250173)])})\n"
     ]
    }
   ],
   "source": [
    "categorical_features_threshold = {\"site_id\": 5000, \"visitor_location_country_id\": 1000, \"prop_country_id\": 1000, \"srch_destination_id\": 5000}\n",
    "feature_tester = FeatureTester(lgbm_class_model, categorical_features_threshold= categorical_features_threshold)\n",
    "\n",
    "impute_null_columns_methods = [{'prop_review_score': 'median', 'orig_destination_distance': 'mean'}]\n",
    "feature_tester.test_na_fill_method(impute_null_columns_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_light_feature_filtered = FeatureTester(lgbm_class_model).light_feature_filtering(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39606b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:43:32,315] A new study created in memory with name: no-name-5ecd838f-e43a-441e-8b91-57a04ce276c8\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.383736\n",
      "[200]\tvalid_0's ndcg@5: 0.389339\n",
      "[300]\tvalid_0's ndcg@5: 0.392949\n",
      "[400]\tvalid_0's ndcg@5: 0.394882\n",
      "[500]\tvalid_0's ndcg@5: 0.396759\n",
      "[600]\tvalid_0's ndcg@5: 0.398077\n",
      "[700]\tvalid_0's ndcg@5: 0.399094\n",
      "[800]\tvalid_0's ndcg@5: 0.399986\n",
      "[900]\tvalid_0's ndcg@5: 0.400656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:46:19,112] Trial 0 finished with value: 0.4009588473731571 and parameters: {'learning_rate': 0.029206366231730486, 'num_leaves': 51, 'min_child_samples': 42, 'reg_alpha': 0.03241908228604195, 'reg_lambda': 0.00599897408668521}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.400636\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[982]\tvalid_0's ndcg@5: 0.400959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.383279\n",
      "[200]\tvalid_0's ndcg@5: 0.389857\n",
      "[300]\tvalid_0's ndcg@5: 0.3936\n",
      "[400]\tvalid_0's ndcg@5: 0.395975\n",
      "[500]\tvalid_0's ndcg@5: 0.397248\n",
      "[600]\tvalid_0's ndcg@5: 0.398331\n",
      "[700]\tvalid_0's ndcg@5: 0.398452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:48:01,086] Trial 1 finished with value: 0.39889193751085517 and parameters: {'learning_rate': 0.04720022094068139, 'num_leaves': 29, 'min_child_samples': 12, 'reg_alpha': 0.0095366939014647, 'reg_lambda': 0.03594175655080545}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[637]\tvalid_0's ndcg@5: 0.398892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.381511\n",
      "[200]\tvalid_0's ndcg@5: 0.385849\n",
      "[300]\tvalid_0's ndcg@5: 0.389425\n",
      "[400]\tvalid_0's ndcg@5: 0.392149\n",
      "[500]\tvalid_0's ndcg@5: 0.39419\n",
      "[600]\tvalid_0's ndcg@5: 0.395696\n",
      "[700]\tvalid_0's ndcg@5: 0.397127\n",
      "[800]\tvalid_0's ndcg@5: 0.398198\n",
      "[900]\tvalid_0's ndcg@5: 0.399042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:51:39,316] Trial 2 finished with value: 0.39948519619737677 and parameters: {'learning_rate': 0.013542017679581877, 'num_leaves': 95, 'min_child_samples': 15, 'reg_alpha': 0.5562814026113791, 'reg_lambda': 0.0015277471763877298}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.399259\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[943]\tvalid_0's ndcg@5: 0.399485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.375926\n",
      "[200]\tvalid_0's ndcg@5: 0.379666\n",
      "[300]\tvalid_0's ndcg@5: 0.383862\n",
      "[400]\tvalid_0's ndcg@5: 0.386514\n",
      "[500]\tvalid_0's ndcg@5: 0.388331\n",
      "[600]\tvalid_0's ndcg@5: 0.389746\n",
      "[700]\tvalid_0's ndcg@5: 0.390904\n",
      "[800]\tvalid_0's ndcg@5: 0.391849\n",
      "[900]\tvalid_0's ndcg@5: 0.393104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:54:38,605] Trial 3 finished with value: 0.39401282630855594 and parameters: {'learning_rate': 0.012936654346080712, 'num_leaves': 36, 'min_child_samples': 43, 'reg_alpha': 0.15637005853374714, 'reg_lambda': 0.0051805496660579575}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.393913\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's ndcg@5: 0.394013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.39464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:55:13,695] Trial 4 finished with value: 0.39587105413380813 and parameters: {'learning_rate': 0.19382185199993987, 'num_leaves': 72, 'min_child_samples': 10, 'reg_alpha': 0.11639503817363493, 'reg_lambda': 0.011961808770327495}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's ndcg@5: 0.394595\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's ndcg@5: 0.395871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.381355\n",
      "[200]\tvalid_0's ndcg@5: 0.385588\n",
      "[300]\tvalid_0's ndcg@5: 0.388956\n",
      "[400]\tvalid_0's ndcg@5: 0.391517\n",
      "[500]\tvalid_0's ndcg@5: 0.393028\n",
      "[600]\tvalid_0's ndcg@5: 0.395086\n",
      "[700]\tvalid_0's ndcg@5: 0.396228\n",
      "[800]\tvalid_0's ndcg@5: 0.397358\n",
      "[900]\tvalid_0's ndcg@5: 0.397992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:58:54,349] Trial 5 finished with value: 0.39907707134553505 and parameters: {'learning_rate': 0.012895075387557103, 'num_leaves': 89, 'min_child_samples': 24, 'reg_alpha': 0.06285625720101184, 'reg_lambda': 0.057171476840371806}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.399077\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's ndcg@5: 0.399077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.380485\n",
      "[200]\tvalid_0's ndcg@5: 0.387071\n",
      "[300]\tvalid_0's ndcg@5: 0.390368\n",
      "[400]\tvalid_0's ndcg@5: 0.392981\n",
      "[500]\tvalid_0's ndcg@5: 0.395401\n",
      "[600]\tvalid_0's ndcg@5: 0.396225\n",
      "[700]\tvalid_0's ndcg@5: 0.39661\n",
      "[800]\tvalid_0's ndcg@5: 0.397052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:00:41,758] Trial 6 finished with value: 0.39726795605561255 and parameters: {'learning_rate': 0.056526011275308735, 'num_leaves': 16, 'min_child_samples': 50, 'reg_alpha': 0.16004474688420434, 'reg_lambda': 0.030744774590195756}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[812]\tvalid_0's ndcg@5: 0.397268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.377559\n",
      "[200]\tvalid_0's ndcg@5: 0.382341\n",
      "[300]\tvalid_0's ndcg@5: 0.385229\n",
      "[400]\tvalid_0's ndcg@5: 0.387713\n",
      "[500]\tvalid_0's ndcg@5: 0.389759\n",
      "[600]\tvalid_0's ndcg@5: 0.391454\n",
      "[700]\tvalid_0's ndcg@5: 0.392759\n",
      "[800]\tvalid_0's ndcg@5: 0.393831\n",
      "[900]\tvalid_0's ndcg@5: 0.394799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:03:41,021] Trial 7 finished with value: 0.39589934647269603 and parameters: {'learning_rate': 0.015667401526455335, 'num_leaves': 36, 'min_child_samples': 38, 'reg_alpha': 0.0022147219312397388, 'reg_lambda': 0.00026784822199269446}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.395827\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[992]\tvalid_0's ndcg@5: 0.395899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.394885\n",
      "[200]\tvalid_0's ndcg@5: 0.399046\n",
      "[300]\tvalid_0's ndcg@5: 0.399429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:04:47,833] Trial 8 finished with value: 0.3997137207592745 and parameters: {'learning_rate': 0.08348809330356485, 'num_leaves': 96, 'min_child_samples': 17, 'reg_alpha': 0.0011378927776504197, 'reg_lambda': 0.00029657903823331473}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[281]\tvalid_0's ndcg@5: 0.399714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.393433\n",
      "[200]\tvalid_0's ndcg@5: 0.398663\n",
      "[300]\tvalid_0's ndcg@5: 0.398646\n",
      "[400]\tvalid_0's ndcg@5: 0.398652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:05:50,230] Trial 9 finished with value: 0.399147568218633 and parameters: {'learning_rate': 0.10430622117821092, 'num_leaves': 59, 'min_child_samples': 10, 'reg_alpha': 0.7673277832357333, 'reg_lambda': 0.0019164678639036195}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's ndcg@5: 0.399148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.38442\n",
      "[200]\tvalid_0's ndcg@5: 0.389607\n",
      "[300]\tvalid_0's ndcg@5: 0.392611\n",
      "[400]\tvalid_0's ndcg@5: 0.395037\n",
      "[500]\tvalid_0's ndcg@5: 0.396727\n",
      "[600]\tvalid_0's ndcg@5: 0.398142\n",
      "[700]\tvalid_0's ndcg@5: 0.398974\n",
      "[800]\tvalid_0's ndcg@5: 0.399684\n",
      "[900]\tvalid_0's ndcg@5: 0.400054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:08:51,190] Trial 10 finished with value: 0.4006210193900112 and parameters: {'learning_rate': 0.022462956519729887, 'num_leaves': 55, 'min_child_samples': 34, 'reg_alpha': 0.00031863928107496675, 'reg_lambda': 0.5357581691295416}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.400598\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's ndcg@5: 0.400621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.387203\n",
      "[200]\tvalid_0's ndcg@5: 0.391849\n",
      "[300]\tvalid_0's ndcg@5: 0.395323\n",
      "[400]\tvalid_0's ndcg@5: 0.39852\n",
      "[500]\tvalid_0's ndcg@5: 0.399652\n",
      "[600]\tvalid_0's ndcg@5: 0.400826\n",
      "[700]\tvalid_0's ndcg@5: 0.401449\n",
      "[800]\tvalid_0's ndcg@5: 0.402421\n",
      "[900]\tvalid_0's ndcg@5: 0.403333\n",
      "[1000]\tvalid_0's ndcg@5: 0.403971\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's ndcg@5: 0.40399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:11:44,735] Trial 11 finished with value: 0.4039896905899076 and parameters: {'learning_rate': 0.026083374379090425, 'num_leaves': 55, 'min_child_samples': 33, 'reg_alpha': 0.0001930449152698261, 'reg_lambda': 0.9799587667799275}. Best is trial 11 with value: 0.4039896905899076.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.383611\n",
      "[200]\tvalid_0's ndcg@5: 0.389369\n",
      "[300]\tvalid_0's ndcg@5: 0.393009\n",
      "[400]\tvalid_0's ndcg@5: 0.395189\n",
      "[500]\tvalid_0's ndcg@5: 0.396688\n",
      "[600]\tvalid_0's ndcg@5: 0.398203\n",
      "[700]\tvalid_0's ndcg@5: 0.399218\n",
      "[800]\tvalid_0's ndcg@5: 0.399848\n",
      "[900]\tvalid_0's ndcg@5: 0.400257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:14:32,777] Trial 12 finished with value: 0.4005004701888286 and parameters: {'learning_rate': 0.026933010531168203, 'num_leaves': 52, 'min_child_samples': 27, 'reg_alpha': 0.014774122836996336, 'reg_lambda': 0.8111609602065704}. Best is trial 11 with value: 0.4039896905899076.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[871]\tvalid_0's ndcg@5: 0.4005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388248\n",
      "[200]\tvalid_0's ndcg@5: 0.394673\n",
      "[300]\tvalid_0's ndcg@5: 0.397557\n",
      "[400]\tvalid_0's ndcg@5: 0.400096\n",
      "[500]\tvalid_0's ndcg@5: 0.401773\n",
      "[600]\tvalid_0's ndcg@5: 0.403179\n",
      "[700]\tvalid_0's ndcg@5: 0.403888\n",
      "[800]\tvalid_0's ndcg@5: 0.404238\n",
      "Early stopping, best iteration is:\n",
      "[779]\tvalid_0's ndcg@5: 0.404486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:17:08,547] Trial 13 finished with value: 0.40448630407043246 and parameters: {'learning_rate': 0.029870745606336475, 'num_leaves': 72, 'min_child_samples': 43, 'reg_alpha': 0.00011295301061647733, 'reg_lambda': 0.28036648530362}. Best is trial 13 with value: 0.40448630407043246.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.389597\n",
      "[200]\tvalid_0's ndcg@5: 0.395373\n",
      "[300]\tvalid_0's ndcg@5: 0.398909\n",
      "[400]\tvalid_0's ndcg@5: 0.400501\n",
      "[500]\tvalid_0's ndcg@5: 0.402226\n",
      "[600]\tvalid_0's ndcg@5: 0.403198\n",
      "[700]\tvalid_0's ndcg@5: 0.403882\n",
      "[800]\tvalid_0's ndcg@5: 0.404678\n",
      "[900]\tvalid_0's ndcg@5: 0.405013\n",
      "[1000]\tvalid_0's ndcg@5: 0.405259\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's ndcg@5: 0.405259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:19:56,559] Trial 14 finished with value: 0.4052591325812726 and parameters: {'learning_rate': 0.03212974505101879, 'num_leaves': 73, 'min_child_samples': 50, 'reg_alpha': 0.00011040479862262133, 'reg_lambda': 0.24732993458766012}. Best is trial 14 with value: 0.4052591325812726.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.390246\n",
      "[200]\tvalid_0's ndcg@5: 0.39566\n",
      "[300]\tvalid_0's ndcg@5: 0.398685\n",
      "[400]\tvalid_0's ndcg@5: 0.401075\n",
      "[500]\tvalid_0's ndcg@5: 0.402412\n",
      "[600]\tvalid_0's ndcg@5: 0.403925\n",
      "[700]\tvalid_0's ndcg@5: 0.404591\n",
      "[800]\tvalid_0's ndcg@5: 0.405285\n",
      "[900]\tvalid_0's ndcg@5: 0.405544\n",
      "Early stopping, best iteration is:\n",
      "[839]\tvalid_0's ndcg@5: 0.405768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:22:29,667] Trial 15 finished with value: 0.4057677345356311 and parameters: {'learning_rate': 0.03427673821049949, 'num_leaves': 79, 'min_child_samples': 50, 'reg_alpha': 0.0001416721648867782, 'reg_lambda': 0.12245976197134716}. Best is trial 15 with value: 0.4057677345356311.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.392684\n",
      "[200]\tvalid_0's ndcg@5: 0.397949\n",
      "[300]\tvalid_0's ndcg@5: 0.400487\n",
      "[400]\tvalid_0's ndcg@5: 0.401208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:23:51,771] Trial 16 finished with value: 0.4013397529321886 and parameters: {'learning_rate': 0.06797569109769427, 'num_leaves': 80, 'min_child_samples': 50, 'reg_alpha': 0.0006892566073834891, 'reg_lambda': 0.17544031971677385}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[395]\tvalid_0's ndcg@5: 0.40134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388436\n",
      "[200]\tvalid_0's ndcg@5: 0.394117\n",
      "[300]\tvalid_0's ndcg@5: 0.39776\n",
      "[400]\tvalid_0's ndcg@5: 0.399813\n",
      "[500]\tvalid_0's ndcg@5: 0.401461\n",
      "[600]\tvalid_0's ndcg@5: 0.401736\n",
      "[700]\tvalid_0's ndcg@5: 0.402383\n",
      "[800]\tvalid_0's ndcg@5: 0.402516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:26:17,602] Trial 17 finished with value: 0.4025997518117463 and parameters: {'learning_rate': 0.03985660926136615, 'num_leaves': 78, 'min_child_samples': 47, 'reg_alpha': 0.0019677305487627236, 'reg_lambda': 0.1215779399859642}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[767]\tvalid_0's ndcg@5: 0.4026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.382837\n",
      "[200]\tvalid_0's ndcg@5: 0.388186\n",
      "[300]\tvalid_0's ndcg@5: 0.390885\n",
      "[400]\tvalid_0's ndcg@5: 0.393432\n",
      "[500]\tvalid_0's ndcg@5: 0.395477\n",
      "[600]\tvalid_0's ndcg@5: 0.397351\n",
      "[700]\tvalid_0's ndcg@5: 0.398021\n",
      "[800]\tvalid_0's ndcg@5: 0.398955\n",
      "[900]\tvalid_0's ndcg@5: 0.399891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:29:36,402] Trial 18 finished with value: 0.40086916893679925 and parameters: {'learning_rate': 0.01955484462093037, 'num_leaves': 65, 'min_child_samples': 38, 'reg_alpha': 0.0003728244272196691, 'reg_lambda': 0.07559873057658555}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.400465\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[965]\tvalid_0's ndcg@5: 0.400869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388299\n",
      "[200]\tvalid_0's ndcg@5: 0.393566\n",
      "[300]\tvalid_0's ndcg@5: 0.397211\n",
      "[400]\tvalid_0's ndcg@5: 0.399158\n",
      "[500]\tvalid_0's ndcg@5: 0.400275\n",
      "[600]\tvalid_0's ndcg@5: 0.400818\n",
      "[700]\tvalid_0's ndcg@5: 0.400835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:31:52,320] Trial 19 finished with value: 0.401211760995312 and parameters: {'learning_rate': 0.03842325963893739, 'num_leaves': 85, 'min_child_samples': 46, 'reg_alpha': 0.003049684065392254, 'reg_lambda': 0.24833554529545002}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[649]\tvalid_0's ndcg@5: 0.401212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.398698\n",
      "[200]\tvalid_0's ndcg@5: 0.400196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:32:39,513] Trial 20 finished with value: 0.4006004622649478 and parameters: {'learning_rate': 0.1393838793730853, 'num_leaves': 68, 'min_child_samples': 38, 'reg_alpha': 0.000126136018883213, 'reg_lambda': 0.023034585811162845}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's ndcg@5: 0.4006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.390333\n",
      "[200]\tvalid_0's ndcg@5: 0.396254\n",
      "[300]\tvalid_0's ndcg@5: 0.398674\n",
      "[400]\tvalid_0's ndcg@5: 0.400561\n",
      "[500]\tvalid_0's ndcg@5: 0.40267\n",
      "[600]\tvalid_0's ndcg@5: 0.403752\n",
      "[700]\tvalid_0's ndcg@5: 0.404587\n",
      "[800]\tvalid_0's ndcg@5: 0.405072\n",
      "[900]\tvalid_0's ndcg@5: 0.405196\n",
      "Early stopping, best iteration is:\n",
      "[894]\tvalid_0's ndcg@5: 0.405417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:35:32,198] Trial 21 finished with value: 0.40541725522476846 and parameters: {'learning_rate': 0.03466770550543203, 'num_leaves': 73, 'min_child_samples': 44, 'reg_alpha': 0.00012543712974830048, 'reg_lambda': 0.29739747325158855}. Best is trial 15 with value: 0.4057677345356311.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.387214\n",
      "[200]\tvalid_0's ndcg@5: 0.39308\n",
      "[300]\tvalid_0's ndcg@5: 0.396608\n",
      "[400]\tvalid_0's ndcg@5: 0.39865\n",
      "[500]\tvalid_0's ndcg@5: 0.400241\n",
      "[600]\tvalid_0's ndcg@5: 0.401439\n",
      "[700]\tvalid_0's ndcg@5: 0.401746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:38:38,060] Trial 22 finished with value: 0.40193685819188596 and parameters: {'learning_rate': 0.03592953121675618, 'num_leaves': 80, 'min_child_samples': 47, 'reg_alpha': 0.0005987923365429163, 'reg_lambda': 0.43891501079164835}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's ndcg@5: 0.401937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.392352\n",
      "[200]\tvalid_0's ndcg@5: 0.397052\n",
      "[300]\tvalid_0's ndcg@5: 0.399086\n",
      "[400]\tvalid_0's ndcg@5: 0.401079\n",
      "[500]\tvalid_0's ndcg@5: 0.401734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:40:25,916] Trial 23 finished with value: 0.4018935484633709 and parameters: {'learning_rate': 0.05408549012199238, 'num_leaves': 63, 'min_child_samples': 50, 'reg_alpha': 0.0002925858864918027, 'reg_lambda': 0.127063836188334}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[493]\tvalid_0's ndcg@5: 0.401894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.386856\n",
      "[200]\tvalid_0's ndcg@5: 0.392402\n",
      "[300]\tvalid_0's ndcg@5: 0.395153\n",
      "[400]\tvalid_0's ndcg@5: 0.397971\n",
      "[500]\tvalid_0's ndcg@5: 0.399838\n",
      "[600]\tvalid_0's ndcg@5: 0.400692\n",
      "[700]\tvalid_0's ndcg@5: 0.402224\n",
      "[800]\tvalid_0's ndcg@5: 0.403677\n",
      "[900]\tvalid_0's ndcg@5: 0.404206\n",
      "[1000]\tvalid_0's ndcg@5: 0.404904\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's ndcg@5: 0.404907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:44:05,928] Trial 24 finished with value: 0.40490669834914206 and parameters: {'learning_rate': 0.020463917189215124, 'num_leaves': 88, 'min_child_samples': 45, 'reg_alpha': 0.000120306548764845, 'reg_lambda': 0.3214803793186365}. Best is trial 15 with value: 0.4057677345356311.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.384988\n",
      "[200]\tvalid_0's ndcg@5: 0.390514\n",
      "[300]\tvalid_0's ndcg@5: 0.393514\n",
      "[400]\tvalid_0's ndcg@5: 0.395159\n",
      "[500]\tvalid_0's ndcg@5: 0.397002\n",
      "[600]\tvalid_0's ndcg@5: 0.398392\n",
      "[700]\tvalid_0's ndcg@5: 0.399331\n",
      "[800]\tvalid_0's ndcg@5: 0.399658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:46:34,865] Trial 25 finished with value: 0.3997341751181645 and parameters: {'learning_rate': 0.03431341673247756, 'num_leaves': 45, 'min_child_samples': 40, 'reg_alpha': 0.0008808590150802879, 'reg_lambda': 0.07135488188807257}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[722]\tvalid_0's ndcg@5: 0.399734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.392152\n",
      "[200]\tvalid_0's ndcg@5: 0.397074\n",
      "[300]\tvalid_0's ndcg@5: 0.400225\n",
      "[400]\tvalid_0's ndcg@5: 0.401855\n",
      "[500]\tvalid_0's ndcg@5: 0.402678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:48:31,732] Trial 26 finished with value: 0.40270345985903505 and parameters: {'learning_rate': 0.04857825718604731, 'num_leaves': 74, 'min_child_samples': 34, 'reg_alpha': 0.00024315805246685464, 'reg_lambda': 0.013931286166211327}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[493]\tvalid_0's ndcg@5: 0.402703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.392281\n",
      "[200]\tvalid_0's ndcg@5: 0.39807\n",
      "[300]\tvalid_0's ndcg@5: 0.399579\n",
      "[400]\tvalid_0's ndcg@5: 0.40005\n",
      "[500]\tvalid_0's ndcg@5: 0.400827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:50:28,560] Trial 27 finished with value: 0.4012347874151322 and parameters: {'learning_rate': 0.06834306068366106, 'num_leaves': 88, 'min_child_samples': 47, 'reg_alpha': 0.003929761173523843, 'reg_lambda': 0.14036489833255963}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[484]\tvalid_0's ndcg@5: 0.401235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.383592\n",
      "[200]\tvalid_0's ndcg@5: 0.388443\n",
      "[300]\tvalid_0's ndcg@5: 0.391863\n",
      "[400]\tvalid_0's ndcg@5: 0.393852\n",
      "[500]\tvalid_0's ndcg@5: 0.396411\n",
      "[600]\tvalid_0's ndcg@5: 0.39738\n",
      "[700]\tvalid_0's ndcg@5: 0.398861\n",
      "[800]\tvalid_0's ndcg@5: 0.400073\n",
      "[900]\tvalid_0's ndcg@5: 0.400694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:55:48,698] Trial 28 finished with value: 0.40184864442504553 and parameters: {'learning_rate': 0.017052363412740197, 'num_leaves': 98, 'min_child_samples': 24, 'reg_alpha': 0.0004954193987243282, 'reg_lambda': 0.6532867831676925}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.401849\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's ndcg@5: 0.401849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.38303\n",
      "[200]\tvalid_0's ndcg@5: 0.387965\n",
      "[300]\tvalid_0's ndcg@5: 0.391606\n",
      "[400]\tvalid_0's ndcg@5: 0.393943\n",
      "[500]\tvalid_0's ndcg@5: 0.395791\n",
      "[600]\tvalid_0's ndcg@5: 0.397425\n",
      "[700]\tvalid_0's ndcg@5: 0.398565\n",
      "[800]\tvalid_0's ndcg@5: 0.399429\n",
      "[900]\tvalid_0's ndcg@5: 0.399464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 19:00:35,519] Trial 29 finished with value: 0.3999218177279299 and parameters: {'learning_rate': 0.022977417720309055, 'num_leaves': 62, 'min_child_samples': 40, 'reg_alpha': 0.0012959217136057817, 'reg_lambda': 0.04784958443914961}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[863]\tvalid_0's ndcg@5: 0.399922\n",
      "Best trial:\n",
      "FrozenTrial(number=15, state=TrialState.COMPLETE, values=[0.4057677345356311], datetime_start=datetime.datetime(2025, 5, 12, 18, 19, 56, 560111), datetime_complete=datetime.datetime(2025, 5, 12, 18, 22, 29, 667330), params={'learning_rate': 0.03427673821049949, 'num_leaves': 79, 'min_child_samples': 50, 'reg_alpha': 0.0001416721648867782, 'reg_lambda': 0.12245976197134716}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.2, log=True, low=0.01, step=None), 'num_leaves': IntDistribution(high=100, log=False, low=10, step=1), 'min_child_samples': IntDistribution(high=50, log=False, low=10, step=1), 'reg_alpha': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=1.0, log=True, low=0.0001, step=None)}, trial_id=15, value=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.03427673821049949,\n",
       " 'num_leaves': 79,\n",
       " 'min_child_samples': 50,\n",
       " 'reg_alpha': 0.0001416721648867782,\n",
       " 'reg_lambda': 0.12245976197134716}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_ranker_model = LGBMRankerModel(train_df)\n",
    "feature_tester = FeatureTester(lgbm_ranker_model)\n",
    "X_train, y_train, X_val, y_val, groups_size_train, groups_size_val = lgbm_ranker_model.format_data(train_df)\n",
    "# Run light hpo\n",
    "feature_tester.run_light_hpo(X_train, y_train, X_val, y_val, groups_size_train, groups_size_val, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb87f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.334616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5677\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 99\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.402751\n",
      "[750]\tvalid_0's ndcg@5: 0.404563\n",
      "Early stopping, best iteration is:\n",
      "[759]\tvalid_0's ndcg@5: 0.404779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.248218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5505\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 50\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.396975\n",
      "[500]\tvalid_0's ndcg@5: 0.401948\n",
      "[750]\tvalid_0's ndcg@5: 0.404328\n",
      "Early stopping, best iteration is:\n",
      "[775]\tvalid_0's ndcg@5: 0.404599\n",
      "Top 50 features: NDCG@5 = 0.4046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.265350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5521\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 53\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397545\n",
      "[500]\tvalid_0's ndcg@5: 0.402349\n",
      "[750]\tvalid_0's ndcg@5: 0.404547\n",
      "Early stopping, best iteration is:\n",
      "[824]\tvalid_0's ndcg@5: 0.405097\n",
      "Top 53 features: NDCG@5 = 0.4051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.287199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5559\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 56\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.401948\n",
      "[750]\tvalid_0's ndcg@5: 0.404332\n",
      "Early stopping, best iteration is:\n",
      "[839]\tvalid_0's ndcg@5: 0.40469\n",
      "Top 56 features: NDCG@5 = 0.4047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.277580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5572\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 59\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.402533\n",
      "[750]\tvalid_0's ndcg@5: 0.40503\n",
      "Early stopping, best iteration is:\n",
      "[870]\tvalid_0's ndcg@5: 0.405892\n",
      "Top 59 features: NDCG@5 = 0.4059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.252419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5578\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 62\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.402533\n",
      "[750]\tvalid_0's ndcg@5: 0.40503\n",
      "Early stopping, best iteration is:\n",
      "[870]\tvalid_0's ndcg@5: 0.405892\n",
      "Top 62 features: NDCG@5 = 0.4059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.278093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5590\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 65\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.40241\n",
      "[750]\tvalid_0's ndcg@5: 0.404411\n",
      "Early stopping, best iteration is:\n",
      "[786]\tvalid_0's ndcg@5: 0.404677\n",
      "Top 65 features: NDCG@5 = 0.4047\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(\"data/training_set_processed.parquet\")\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [5],\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.03427673821049949,\n",
    "    'num_leaves': 79,\n",
    "    'min_child_samples': 50,\n",
    "    'reg_alpha': 0.0001416721648867782,\n",
    "    'reg_lambda': 0.12245976197134716\n",
    "}\n",
    "lgbm_class_model = LGBMRankerModel(df = train_df, **params)\n",
    "feature_tester = FeatureTester(lgbm_class_model, \n",
    "                               categorical_features_threshold={\"site_id\": 5000, \"visitor_location_country_id\": 1000, \"prop_country_id\": 1000, \"srch_destination_id\": 5000},\n",
    "                               impute_null_columns={'prop_review_score': 'median', 'orig_destination_distance': 'mean'})\n",
    "results = feature_tester.full_feature_selection(train_df, feature_counts = list(range(50, 66, 3)), params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a67c0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ff81d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.404599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.405097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>0.404690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>0.405892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.405892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65</td>\n",
       "      <td>0.404677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1\n",
       "0  50  0.404599\n",
       "1  53  0.405097\n",
       "2  56  0.404690\n",
       "3  59  0.405892\n",
       "4  62  0.405892\n",
       "5  65  0.404677"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ed7764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_parquet(\"data/feature_selection_results_even_more_zoomed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18841da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 13:50:33,531] A new study created in memory with name: no-name-0ef7a741-0e1b-4744-91b9-8a5219257d53\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.381693\n",
      "[500]\tvalid_0's ndcg@5: 0.388191\n",
      "[750]\tvalid_0's ndcg@5: 0.39174\n",
      "[1000]\tvalid_0's ndcg@5: 0.393553\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[991]\tvalid_0's ndcg@5: 0.393826\n",
      "Best Score for fold: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.3938261189064282)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-05-15 13:52:39,371] Trial 0 failed with parameters: {'learning_rate': 0.016526549050134516, 'num_leaves': 25, 'min_child_samples': 52, 'min_child_weight': 0.18137325386268616, 'colsample_bytree': 0.8155711535175225, 'subsample': 0.5825473665973167, 'reg_alpha': 1.7547851369785892, 'reg_lambda': 1.357180679562033} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/Users/rik/Documents/VU/DMT/DataMiningTechniquesA2/feature_tester.py\", line 230, in <lambda>\n",
      "    study.optimize(lambda trial: self.full_hpo_objective(trial, X, y, groups), n_trials=n_trials)\n",
      "  File \"/Users/rik/Documents/VU/DMT/DataMiningTechniquesA2/feature_tester.py\", line 213, in full_hpo_objective\n",
      "    model.fit(\n",
      "  File \"/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1780, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/basic.py\", line 4155, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-15 13:52:39,373] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m lgbm_class_model \u001b[38;5;241m=\u001b[39m LGBMRankerModel(\n\u001b[1;32m      2\u001b[0m     df \u001b[38;5;241m=\u001b[39m train_df,\n\u001b[1;32m      3\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambdarank\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     reg_lambda\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.12245976197134716\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m feature_tester \u001b[38;5;241m=\u001b[39m FeatureTester(lgbm_class_model)\n\u001b[0;32m---> 14\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_tester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_full_hpo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_value)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/Documents/VU/DMT/DataMiningTechniquesA2/feature_tester.py:230\u001b[0m, in \u001b[0;36mFeatureTester.run_full_hpo\u001b[0;34m(self, df, n_trials)\u001b[0m\n\u001b[1;32m    228\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    229\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_X_y_groups(df)\n\u001b[0;32m--> 230\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_hpo_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/Documents/VU/DMT/DataMiningTechniquesA2/feature_tester.py:230\u001b[0m, in \u001b[0;36mFeatureTester.run_full_hpo.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    228\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    229\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_X_y_groups(df)\n\u001b[0;32m--> 230\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_hpo_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39mn_trials)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m~/Documents/VU/DMT/DataMiningTechniquesA2/feature_tester.py:213\u001b[0m, in \u001b[0;36mFeatureTester.full_hpo_objective\u001b[0;34m(self, trial, X, y, groups, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    210\u001b[0m groups_size_val \u001b[38;5;241m=\u001b[39m groups_size_val[groups_size_val \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    212\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMRanker(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 213\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups_size_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mgroups_size_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Score for fold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    222\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbest_score_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_0\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndcg@5\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:1780\u001b[0m, in \u001b[0;36mLGBMRanker.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, eval_at, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1775\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould set group for all eval datasets for ranking task; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1776\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif you use dict, the index should start from 0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1777\u001b[0m         )\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_at \u001b[38;5;241m=\u001b[39m eval_at\n\u001b[0;32m-> 1780\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    311\u001b[0m     cb(\n\u001b[1;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4154\u001b[0m _safe_call(\n\u001b[0;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4159\u001b[0m )\n\u001b[1;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgbm_class_model = LGBMRankerModel(\n",
    "    df = train_df,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[5],\n",
    "    n_estimators=1000,\n",
    "    learning_rate= 0.03427673821049949,\n",
    "    num_leaves= 79,\n",
    "    min_child_samples=50,\n",
    "    reg_alpha= 0.0001416721648867782,\n",
    "    reg_lambda= 0.12245976197134716\n",
    ")\n",
    "feature_tester = FeatureTester(lgbm_class_model)\n",
    "study = feature_tester.run_full_hpo(train_df, n_trials=50)\n",
    "print(\"Best score:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
