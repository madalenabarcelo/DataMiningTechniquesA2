{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e882a1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path (/Users/rik/Documents/VU/DMT/DataMiningTechniquesA2) already exists in sys.path\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run ./initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4cd098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lgbm_ranker import LGBMRankerModel, LGBMRanker\n",
    "from feature_tester import FeatureTester\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940224a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"data/training_set_processed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674af584",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_class_model = LGBMRankerModel(\n",
    "    df = train_df,              # Only initialized to get column names\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[5],\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da4de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.362862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7548\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.389358\n",
      "[200]\tvalid_0's ndcg@5: 0.395328\n",
      "[300]\tvalid_0's ndcg@5: 0.397886\n",
      "[400]\tvalid_0's ndcg@5: 0.399382\n",
      "[500]\tvalid_0's ndcg@5: 0.400988\n",
      "Early stopping, best iteration is:\n",
      "[497]\tvalid_0's ndcg@5: 0.40125\n",
      "Model trained successfully with the following categorical features threshold: {'srch_destination_id': 1000}\n",
      "Number of categories for srch_destination_id: 899\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.4012500931985614)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.352134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8181\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388299\n",
      "[200]\tvalid_0's ndcg@5: 0.393923\n",
      "[300]\tvalid_0's ndcg@5: 0.397105\n",
      "[400]\tvalid_0's ndcg@5: 0.398465\n",
      "[500]\tvalid_0's ndcg@5: 0.399945\n",
      "Early stopping, best iteration is:\n",
      "[488]\tvalid_0's ndcg@5: 0.400113\n",
      "Model trained successfully with the following categorical features threshold: {'srch_destination_id': 500}\n",
      "Number of categories for srch_destination_id: 1598\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.4001131429688723)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.353665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7048\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.389763\n",
      "[200]\tvalid_0's ndcg@5: 0.396331\n",
      "[300]\tvalid_0's ndcg@5: 0.399133\n",
      "[400]\tvalid_0's ndcg@5: 0.400796\n",
      "Early stopping, best iteration is:\n",
      "[447]\tvalid_0's ndcg@5: 0.401635\n",
      "Model trained successfully with the following categorical features threshold: {'srch_destination_id': 2500}\n",
      "Number of categories for srch_destination_id: 365\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.40163484050126586)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.344287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6844\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388319\n",
      "[200]\tvalid_0's ndcg@5: 0.39518\n",
      "[300]\tvalid_0's ndcg@5: 0.398809\n",
      "[400]\tvalid_0's ndcg@5: 0.400643\n",
      "[500]\tvalid_0's ndcg@5: 0.401616\n",
      "[600]\tvalid_0's ndcg@5: 0.402403\n",
      "Early stopping, best iteration is:\n",
      "[575]\tvalid_0's ndcg@5: 0.402631\n",
      "Model trained successfully with the following categorical features threshold: {'srch_destination_id': 5000}\n",
      "Number of categories for srch_destination_id: 142\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.4026305956916656)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.409216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6692\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388356\n",
      "[200]\tvalid_0's ndcg@5: 0.395364\n",
      "[300]\tvalid_0's ndcg@5: 0.398718\n",
      "[400]\tvalid_0's ndcg@5: 0.40098\n",
      "[500]\tvalid_0's ndcg@5: 0.402221\n",
      "[600]\tvalid_0's ndcg@5: 0.403066\n",
      "[700]\tvalid_0's ndcg@5: 0.403962\n",
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's ndcg@5: 0.404127\n",
      "Model trained successfully with the following categorical features threshold: {'site_id': 5000, 'visitor_location_country_id': 1000, 'prop_country_id': 1000, 'srch_destination_id': 5000}\n",
      "Number of categories for site_id: 27\n",
      "Number of categories for visitor_location_country_id: 78\n",
      "Number of categories for prop_country_id: 94\n",
      "Number of categories for srch_destination_id: 142\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.4041274422834456)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.349070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6729\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.389258\n",
      "[200]\tvalid_0's ndcg@5: 0.395881\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m feature_tester \u001b[38;5;241m=\u001b[39m FeatureTester(lgbm_class_model)\n\u001b[1;32m      2\u001b[0m list_of_categorical_features_threshold \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2500\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5000\u001b[39m}, \n\u001b[1;32m      3\u001b[0m                                           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitor_location_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprop_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5000\u001b[39m}, \n\u001b[1;32m      4\u001b[0m                                           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitor_location_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprop_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5000\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitor_location_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprop_country_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrch_destination_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2500\u001b[39m}]\n\u001b[0;32m----> 5\u001b[0m \u001b[43mfeature_tester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_cardinal_reduction_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_of_categorical_features_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/VU/DMT/DataMiningTechniquesA2/feature_tester.py:25\u001b[0m, in \u001b[0;36mFeatureTester.test_cardinal_reduction_methods\u001b[0;34m(self, list_of_categorical_features_threshold)\u001b[0m\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m     24\u001b[0m X_train, y_train, X_val, y_val, groups_size_train, groups_size_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mformat_data(df)\n\u001b[0;32m---> 25\u001b[0m model_opt \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups_size_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups_size_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel trained successfully with the following categorical features threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategorical_features_threshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m categorical_features_threshold:\n",
      "File \u001b[0;32m~/Documents/VU/DMT/DataMiningTechniquesA2/lgbm_ranker.py:80\u001b[0m, in \u001b[0;36mLGBMRankerModel.fit\u001b[0;34m(self, X_train, y_train, X_val, y_val, groups_size_train, groups_size_val, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m fitted_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups_size_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# counts per srch_id\u001b[39;49;00m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mgroups_size_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fitted_model\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:1780\u001b[0m, in \u001b[0;36mLGBMRanker.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, eval_at, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1775\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould set group for all eval datasets for ranking task; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1776\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif you use dict, the index should start from 0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1777\u001b[0m         )\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_at \u001b[38;5;241m=\u001b[39m eval_at\n\u001b[0;32m-> 1780\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    311\u001b[0m     cb(\n\u001b[1;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4154\u001b[0m _safe_call(\n\u001b[0;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4159\u001b[0m )\n\u001b[1;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_tester = FeatureTester(lgbm_class_model)\n",
    "list_of_categorical_features_threshold = [{\"srch_destination_id\": 1000}, {\"srch_destination_id\": 500}, {\"srch_destination_id\": 2500}, {\"srch_destination_id\": 5000}, \n",
    "                                          {\"site_id\": 5000, \"visitor_location_country_id\": 1000, \"prop_country_id\": 1000, \"srch_destination_id\": 5000}, \n",
    "                                          {\"site_id\": 2500, \"visitor_location_country_id\": 500, \"prop_country_id\": 500, \"srch_destination_id\": 5000}, {\"site_id\": 2500, \"visitor_location_country_id\": 500, \"prop_country_id\": 500, \"srch_destination_id\": 2500}]\n",
    "feature_tester.test_cardinal_reduction_methods(list_of_categorical_features_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b36a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.379983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6689\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 110\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.38862\n",
      "[200]\tvalid_0's ndcg@5: 0.395762\n",
      "[300]\tvalid_0's ndcg@5: 0.399033\n",
      "[400]\tvalid_0's ndcg@5: 0.40119\n",
      "[500]\tvalid_0's ndcg@5: 0.402302\n",
      "[600]\tvalid_0's ndcg@5: 0.403876\n",
      "[700]\tvalid_0's ndcg@5: 0.404278\n",
      "[800]\tvalid_0's ndcg@5: 0.404723\n",
      "Early stopping, best iteration is:\n",
      "[795]\tvalid_0's ndcg@5: 0.404954\n",
      "Model trained successfully with imputing the null values for columns: {'prop_review_score': 'median', 'orig_destination_distance': 'mean'}\n",
      "Final result gave the following score on the validation set: defaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('ndcg@5', 0.404954094250173)])})\n"
     ]
    }
   ],
   "source": [
    "categorical_features_threshold = {\"site_id\": 5000, \"visitor_location_country_id\": 1000, \"prop_country_id\": 1000, \"srch_destination_id\": 5000}\n",
    "feature_tester = FeatureTester(lgbm_class_model, categorical_features_threshold= categorical_features_threshold)\n",
    "\n",
    "impute_null_columns_methods = [{'prop_review_score': 'median', 'orig_destination_distance': 'mean'}]\n",
    "feature_tester.test_na_fill_method(impute_null_columns_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_light_feature_filtered = FeatureTester(lgbm_class_model).light_feature_filtering(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e39606b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:43:32,315] A new study created in memory with name: no-name-5ecd838f-e43a-441e-8b91-57a04ce276c8\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.383736\n",
      "[200]\tvalid_0's ndcg@5: 0.389339\n",
      "[300]\tvalid_0's ndcg@5: 0.392949\n",
      "[400]\tvalid_0's ndcg@5: 0.394882\n",
      "[500]\tvalid_0's ndcg@5: 0.396759\n",
      "[600]\tvalid_0's ndcg@5: 0.398077\n",
      "[700]\tvalid_0's ndcg@5: 0.399094\n",
      "[800]\tvalid_0's ndcg@5: 0.399986\n",
      "[900]\tvalid_0's ndcg@5: 0.400656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:46:19,112] Trial 0 finished with value: 0.4009588473731571 and parameters: {'learning_rate': 0.029206366231730486, 'num_leaves': 51, 'min_child_samples': 42, 'reg_alpha': 0.03241908228604195, 'reg_lambda': 0.00599897408668521}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.400636\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[982]\tvalid_0's ndcg@5: 0.400959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.383279\n",
      "[200]\tvalid_0's ndcg@5: 0.389857\n",
      "[300]\tvalid_0's ndcg@5: 0.3936\n",
      "[400]\tvalid_0's ndcg@5: 0.395975\n",
      "[500]\tvalid_0's ndcg@5: 0.397248\n",
      "[600]\tvalid_0's ndcg@5: 0.398331\n",
      "[700]\tvalid_0's ndcg@5: 0.398452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:48:01,086] Trial 1 finished with value: 0.39889193751085517 and parameters: {'learning_rate': 0.04720022094068139, 'num_leaves': 29, 'min_child_samples': 12, 'reg_alpha': 0.0095366939014647, 'reg_lambda': 0.03594175655080545}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[637]\tvalid_0's ndcg@5: 0.398892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.381511\n",
      "[200]\tvalid_0's ndcg@5: 0.385849\n",
      "[300]\tvalid_0's ndcg@5: 0.389425\n",
      "[400]\tvalid_0's ndcg@5: 0.392149\n",
      "[500]\tvalid_0's ndcg@5: 0.39419\n",
      "[600]\tvalid_0's ndcg@5: 0.395696\n",
      "[700]\tvalid_0's ndcg@5: 0.397127\n",
      "[800]\tvalid_0's ndcg@5: 0.398198\n",
      "[900]\tvalid_0's ndcg@5: 0.399042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:51:39,316] Trial 2 finished with value: 0.39948519619737677 and parameters: {'learning_rate': 0.013542017679581877, 'num_leaves': 95, 'min_child_samples': 15, 'reg_alpha': 0.5562814026113791, 'reg_lambda': 0.0015277471763877298}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.399259\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[943]\tvalid_0's ndcg@5: 0.399485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.375926\n",
      "[200]\tvalid_0's ndcg@5: 0.379666\n",
      "[300]\tvalid_0's ndcg@5: 0.383862\n",
      "[400]\tvalid_0's ndcg@5: 0.386514\n",
      "[500]\tvalid_0's ndcg@5: 0.388331\n",
      "[600]\tvalid_0's ndcg@5: 0.389746\n",
      "[700]\tvalid_0's ndcg@5: 0.390904\n",
      "[800]\tvalid_0's ndcg@5: 0.391849\n",
      "[900]\tvalid_0's ndcg@5: 0.393104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:54:38,605] Trial 3 finished with value: 0.39401282630855594 and parameters: {'learning_rate': 0.012936654346080712, 'num_leaves': 36, 'min_child_samples': 43, 'reg_alpha': 0.15637005853374714, 'reg_lambda': 0.0051805496660579575}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.393913\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's ndcg@5: 0.394013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.39464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:55:13,695] Trial 4 finished with value: 0.39587105413380813 and parameters: {'learning_rate': 0.19382185199993987, 'num_leaves': 72, 'min_child_samples': 10, 'reg_alpha': 0.11639503817363493, 'reg_lambda': 0.011961808770327495}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's ndcg@5: 0.394595\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's ndcg@5: 0.395871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.381355\n",
      "[200]\tvalid_0's ndcg@5: 0.385588\n",
      "[300]\tvalid_0's ndcg@5: 0.388956\n",
      "[400]\tvalid_0's ndcg@5: 0.391517\n",
      "[500]\tvalid_0's ndcg@5: 0.393028\n",
      "[600]\tvalid_0's ndcg@5: 0.395086\n",
      "[700]\tvalid_0's ndcg@5: 0.396228\n",
      "[800]\tvalid_0's ndcg@5: 0.397358\n",
      "[900]\tvalid_0's ndcg@5: 0.397992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:58:54,349] Trial 5 finished with value: 0.39907707134553505 and parameters: {'learning_rate': 0.012895075387557103, 'num_leaves': 89, 'min_child_samples': 24, 'reg_alpha': 0.06285625720101184, 'reg_lambda': 0.057171476840371806}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.399077\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's ndcg@5: 0.399077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.380485\n",
      "[200]\tvalid_0's ndcg@5: 0.387071\n",
      "[300]\tvalid_0's ndcg@5: 0.390368\n",
      "[400]\tvalid_0's ndcg@5: 0.392981\n",
      "[500]\tvalid_0's ndcg@5: 0.395401\n",
      "[600]\tvalid_0's ndcg@5: 0.396225\n",
      "[700]\tvalid_0's ndcg@5: 0.39661\n",
      "[800]\tvalid_0's ndcg@5: 0.397052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:00:41,758] Trial 6 finished with value: 0.39726795605561255 and parameters: {'learning_rate': 0.056526011275308735, 'num_leaves': 16, 'min_child_samples': 50, 'reg_alpha': 0.16004474688420434, 'reg_lambda': 0.030744774590195756}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[812]\tvalid_0's ndcg@5: 0.397268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.377559\n",
      "[200]\tvalid_0's ndcg@5: 0.382341\n",
      "[300]\tvalid_0's ndcg@5: 0.385229\n",
      "[400]\tvalid_0's ndcg@5: 0.387713\n",
      "[500]\tvalid_0's ndcg@5: 0.389759\n",
      "[600]\tvalid_0's ndcg@5: 0.391454\n",
      "[700]\tvalid_0's ndcg@5: 0.392759\n",
      "[800]\tvalid_0's ndcg@5: 0.393831\n",
      "[900]\tvalid_0's ndcg@5: 0.394799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:03:41,021] Trial 7 finished with value: 0.39589934647269603 and parameters: {'learning_rate': 0.015667401526455335, 'num_leaves': 36, 'min_child_samples': 38, 'reg_alpha': 0.0022147219312397388, 'reg_lambda': 0.00026784822199269446}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.395827\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[992]\tvalid_0's ndcg@5: 0.395899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.394885\n",
      "[200]\tvalid_0's ndcg@5: 0.399046\n",
      "[300]\tvalid_0's ndcg@5: 0.399429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:04:47,833] Trial 8 finished with value: 0.3997137207592745 and parameters: {'learning_rate': 0.08348809330356485, 'num_leaves': 96, 'min_child_samples': 17, 'reg_alpha': 0.0011378927776504197, 'reg_lambda': 0.00029657903823331473}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[281]\tvalid_0's ndcg@5: 0.399714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.393433\n",
      "[200]\tvalid_0's ndcg@5: 0.398663\n",
      "[300]\tvalid_0's ndcg@5: 0.398646\n",
      "[400]\tvalid_0's ndcg@5: 0.398652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:05:50,230] Trial 9 finished with value: 0.399147568218633 and parameters: {'learning_rate': 0.10430622117821092, 'num_leaves': 59, 'min_child_samples': 10, 'reg_alpha': 0.7673277832357333, 'reg_lambda': 0.0019164678639036195}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's ndcg@5: 0.399148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.38442\n",
      "[200]\tvalid_0's ndcg@5: 0.389607\n",
      "[300]\tvalid_0's ndcg@5: 0.392611\n",
      "[400]\tvalid_0's ndcg@5: 0.395037\n",
      "[500]\tvalid_0's ndcg@5: 0.396727\n",
      "[600]\tvalid_0's ndcg@5: 0.398142\n",
      "[700]\tvalid_0's ndcg@5: 0.398974\n",
      "[800]\tvalid_0's ndcg@5: 0.399684\n",
      "[900]\tvalid_0's ndcg@5: 0.400054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:08:51,190] Trial 10 finished with value: 0.4006210193900112 and parameters: {'learning_rate': 0.022462956519729887, 'num_leaves': 55, 'min_child_samples': 34, 'reg_alpha': 0.00031863928107496675, 'reg_lambda': 0.5357581691295416}. Best is trial 0 with value: 0.4009588473731571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.400598\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's ndcg@5: 0.400621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.387203\n",
      "[200]\tvalid_0's ndcg@5: 0.391849\n",
      "[300]\tvalid_0's ndcg@5: 0.395323\n",
      "[400]\tvalid_0's ndcg@5: 0.39852\n",
      "[500]\tvalid_0's ndcg@5: 0.399652\n",
      "[600]\tvalid_0's ndcg@5: 0.400826\n",
      "[700]\tvalid_0's ndcg@5: 0.401449\n",
      "[800]\tvalid_0's ndcg@5: 0.402421\n",
      "[900]\tvalid_0's ndcg@5: 0.403333\n",
      "[1000]\tvalid_0's ndcg@5: 0.403971\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's ndcg@5: 0.40399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:11:44,735] Trial 11 finished with value: 0.4039896905899076 and parameters: {'learning_rate': 0.026083374379090425, 'num_leaves': 55, 'min_child_samples': 33, 'reg_alpha': 0.0001930449152698261, 'reg_lambda': 0.9799587667799275}. Best is trial 11 with value: 0.4039896905899076.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.383611\n",
      "[200]\tvalid_0's ndcg@5: 0.389369\n",
      "[300]\tvalid_0's ndcg@5: 0.393009\n",
      "[400]\tvalid_0's ndcg@5: 0.395189\n",
      "[500]\tvalid_0's ndcg@5: 0.396688\n",
      "[600]\tvalid_0's ndcg@5: 0.398203\n",
      "[700]\tvalid_0's ndcg@5: 0.399218\n",
      "[800]\tvalid_0's ndcg@5: 0.399848\n",
      "[900]\tvalid_0's ndcg@5: 0.400257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:14:32,777] Trial 12 finished with value: 0.4005004701888286 and parameters: {'learning_rate': 0.026933010531168203, 'num_leaves': 52, 'min_child_samples': 27, 'reg_alpha': 0.014774122836996336, 'reg_lambda': 0.8111609602065704}. Best is trial 11 with value: 0.4039896905899076.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[871]\tvalid_0's ndcg@5: 0.4005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388248\n",
      "[200]\tvalid_0's ndcg@5: 0.394673\n",
      "[300]\tvalid_0's ndcg@5: 0.397557\n",
      "[400]\tvalid_0's ndcg@5: 0.400096\n",
      "[500]\tvalid_0's ndcg@5: 0.401773\n",
      "[600]\tvalid_0's ndcg@5: 0.403179\n",
      "[700]\tvalid_0's ndcg@5: 0.403888\n",
      "[800]\tvalid_0's ndcg@5: 0.404238\n",
      "Early stopping, best iteration is:\n",
      "[779]\tvalid_0's ndcg@5: 0.404486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:17:08,547] Trial 13 finished with value: 0.40448630407043246 and parameters: {'learning_rate': 0.029870745606336475, 'num_leaves': 72, 'min_child_samples': 43, 'reg_alpha': 0.00011295301061647733, 'reg_lambda': 0.28036648530362}. Best is trial 13 with value: 0.40448630407043246.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.389597\n",
      "[200]\tvalid_0's ndcg@5: 0.395373\n",
      "[300]\tvalid_0's ndcg@5: 0.398909\n",
      "[400]\tvalid_0's ndcg@5: 0.400501\n",
      "[500]\tvalid_0's ndcg@5: 0.402226\n",
      "[600]\tvalid_0's ndcg@5: 0.403198\n",
      "[700]\tvalid_0's ndcg@5: 0.403882\n",
      "[800]\tvalid_0's ndcg@5: 0.404678\n",
      "[900]\tvalid_0's ndcg@5: 0.405013\n",
      "[1000]\tvalid_0's ndcg@5: 0.405259\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's ndcg@5: 0.405259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:19:56,559] Trial 14 finished with value: 0.4052591325812726 and parameters: {'learning_rate': 0.03212974505101879, 'num_leaves': 73, 'min_child_samples': 50, 'reg_alpha': 0.00011040479862262133, 'reg_lambda': 0.24732993458766012}. Best is trial 14 with value: 0.4052591325812726.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.390246\n",
      "[200]\tvalid_0's ndcg@5: 0.39566\n",
      "[300]\tvalid_0's ndcg@5: 0.398685\n",
      "[400]\tvalid_0's ndcg@5: 0.401075\n",
      "[500]\tvalid_0's ndcg@5: 0.402412\n",
      "[600]\tvalid_0's ndcg@5: 0.403925\n",
      "[700]\tvalid_0's ndcg@5: 0.404591\n",
      "[800]\tvalid_0's ndcg@5: 0.405285\n",
      "[900]\tvalid_0's ndcg@5: 0.405544\n",
      "Early stopping, best iteration is:\n",
      "[839]\tvalid_0's ndcg@5: 0.405768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:22:29,667] Trial 15 finished with value: 0.4057677345356311 and parameters: {'learning_rate': 0.03427673821049949, 'num_leaves': 79, 'min_child_samples': 50, 'reg_alpha': 0.0001416721648867782, 'reg_lambda': 0.12245976197134716}. Best is trial 15 with value: 0.4057677345356311.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.392684\n",
      "[200]\tvalid_0's ndcg@5: 0.397949\n",
      "[300]\tvalid_0's ndcg@5: 0.400487\n",
      "[400]\tvalid_0's ndcg@5: 0.401208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:23:51,771] Trial 16 finished with value: 0.4013397529321886 and parameters: {'learning_rate': 0.06797569109769427, 'num_leaves': 80, 'min_child_samples': 50, 'reg_alpha': 0.0006892566073834891, 'reg_lambda': 0.17544031971677385}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[395]\tvalid_0's ndcg@5: 0.40134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388436\n",
      "[200]\tvalid_0's ndcg@5: 0.394117\n",
      "[300]\tvalid_0's ndcg@5: 0.39776\n",
      "[400]\tvalid_0's ndcg@5: 0.399813\n",
      "[500]\tvalid_0's ndcg@5: 0.401461\n",
      "[600]\tvalid_0's ndcg@5: 0.401736\n",
      "[700]\tvalid_0's ndcg@5: 0.402383\n",
      "[800]\tvalid_0's ndcg@5: 0.402516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:26:17,602] Trial 17 finished with value: 0.4025997518117463 and parameters: {'learning_rate': 0.03985660926136615, 'num_leaves': 78, 'min_child_samples': 47, 'reg_alpha': 0.0019677305487627236, 'reg_lambda': 0.1215779399859642}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[767]\tvalid_0's ndcg@5: 0.4026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.382837\n",
      "[200]\tvalid_0's ndcg@5: 0.388186\n",
      "[300]\tvalid_0's ndcg@5: 0.390885\n",
      "[400]\tvalid_0's ndcg@5: 0.393432\n",
      "[500]\tvalid_0's ndcg@5: 0.395477\n",
      "[600]\tvalid_0's ndcg@5: 0.397351\n",
      "[700]\tvalid_0's ndcg@5: 0.398021\n",
      "[800]\tvalid_0's ndcg@5: 0.398955\n",
      "[900]\tvalid_0's ndcg@5: 0.399891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:29:36,402] Trial 18 finished with value: 0.40086916893679925 and parameters: {'learning_rate': 0.01955484462093037, 'num_leaves': 65, 'min_child_samples': 38, 'reg_alpha': 0.0003728244272196691, 'reg_lambda': 0.07559873057658555}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.400465\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[965]\tvalid_0's ndcg@5: 0.400869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.388299\n",
      "[200]\tvalid_0's ndcg@5: 0.393566\n",
      "[300]\tvalid_0's ndcg@5: 0.397211\n",
      "[400]\tvalid_0's ndcg@5: 0.399158\n",
      "[500]\tvalid_0's ndcg@5: 0.400275\n",
      "[600]\tvalid_0's ndcg@5: 0.400818\n",
      "[700]\tvalid_0's ndcg@5: 0.400835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:31:52,320] Trial 19 finished with value: 0.401211760995312 and parameters: {'learning_rate': 0.03842325963893739, 'num_leaves': 85, 'min_child_samples': 46, 'reg_alpha': 0.003049684065392254, 'reg_lambda': 0.24833554529545002}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[649]\tvalid_0's ndcg@5: 0.401212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.398698\n",
      "[200]\tvalid_0's ndcg@5: 0.400196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:32:39,513] Trial 20 finished with value: 0.4006004622649478 and parameters: {'learning_rate': 0.1393838793730853, 'num_leaves': 68, 'min_child_samples': 38, 'reg_alpha': 0.000126136018883213, 'reg_lambda': 0.023034585811162845}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's ndcg@5: 0.4006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.390333\n",
      "[200]\tvalid_0's ndcg@5: 0.396254\n",
      "[300]\tvalid_0's ndcg@5: 0.398674\n",
      "[400]\tvalid_0's ndcg@5: 0.400561\n",
      "[500]\tvalid_0's ndcg@5: 0.40267\n",
      "[600]\tvalid_0's ndcg@5: 0.403752\n",
      "[700]\tvalid_0's ndcg@5: 0.404587\n",
      "[800]\tvalid_0's ndcg@5: 0.405072\n",
      "[900]\tvalid_0's ndcg@5: 0.405196\n",
      "Early stopping, best iteration is:\n",
      "[894]\tvalid_0's ndcg@5: 0.405417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:35:32,198] Trial 21 finished with value: 0.40541725522476846 and parameters: {'learning_rate': 0.03466770550543203, 'num_leaves': 73, 'min_child_samples': 44, 'reg_alpha': 0.00012543712974830048, 'reg_lambda': 0.29739747325158855}. Best is trial 15 with value: 0.4057677345356311.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.387214\n",
      "[200]\tvalid_0's ndcg@5: 0.39308\n",
      "[300]\tvalid_0's ndcg@5: 0.396608\n",
      "[400]\tvalid_0's ndcg@5: 0.39865\n",
      "[500]\tvalid_0's ndcg@5: 0.400241\n",
      "[600]\tvalid_0's ndcg@5: 0.401439\n",
      "[700]\tvalid_0's ndcg@5: 0.401746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:38:38,060] Trial 22 finished with value: 0.40193685819188596 and parameters: {'learning_rate': 0.03592953121675618, 'num_leaves': 80, 'min_child_samples': 47, 'reg_alpha': 0.0005987923365429163, 'reg_lambda': 0.43891501079164835}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's ndcg@5: 0.401937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.392352\n",
      "[200]\tvalid_0's ndcg@5: 0.397052\n",
      "[300]\tvalid_0's ndcg@5: 0.399086\n",
      "[400]\tvalid_0's ndcg@5: 0.401079\n",
      "[500]\tvalid_0's ndcg@5: 0.401734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:40:25,916] Trial 23 finished with value: 0.4018935484633709 and parameters: {'learning_rate': 0.05408549012199238, 'num_leaves': 63, 'min_child_samples': 50, 'reg_alpha': 0.0002925858864918027, 'reg_lambda': 0.127063836188334}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[493]\tvalid_0's ndcg@5: 0.401894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.386856\n",
      "[200]\tvalid_0's ndcg@5: 0.392402\n",
      "[300]\tvalid_0's ndcg@5: 0.395153\n",
      "[400]\tvalid_0's ndcg@5: 0.397971\n",
      "[500]\tvalid_0's ndcg@5: 0.399838\n",
      "[600]\tvalid_0's ndcg@5: 0.400692\n",
      "[700]\tvalid_0's ndcg@5: 0.402224\n",
      "[800]\tvalid_0's ndcg@5: 0.403677\n",
      "[900]\tvalid_0's ndcg@5: 0.404206\n",
      "[1000]\tvalid_0's ndcg@5: 0.404904\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's ndcg@5: 0.404907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:44:05,928] Trial 24 finished with value: 0.40490669834914206 and parameters: {'learning_rate': 0.020463917189215124, 'num_leaves': 88, 'min_child_samples': 45, 'reg_alpha': 0.000120306548764845, 'reg_lambda': 0.3214803793186365}. Best is trial 15 with value: 0.4057677345356311.\n",
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.384988\n",
      "[200]\tvalid_0's ndcg@5: 0.390514\n",
      "[300]\tvalid_0's ndcg@5: 0.393514\n",
      "[400]\tvalid_0's ndcg@5: 0.395159\n",
      "[500]\tvalid_0's ndcg@5: 0.397002\n",
      "[600]\tvalid_0's ndcg@5: 0.398392\n",
      "[700]\tvalid_0's ndcg@5: 0.399331\n",
      "[800]\tvalid_0's ndcg@5: 0.399658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:46:34,865] Trial 25 finished with value: 0.3997341751181645 and parameters: {'learning_rate': 0.03431341673247756, 'num_leaves': 45, 'min_child_samples': 40, 'reg_alpha': 0.0008808590150802879, 'reg_lambda': 0.07135488188807257}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[722]\tvalid_0's ndcg@5: 0.399734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.392152\n",
      "[200]\tvalid_0's ndcg@5: 0.397074\n",
      "[300]\tvalid_0's ndcg@5: 0.400225\n",
      "[400]\tvalid_0's ndcg@5: 0.401855\n",
      "[500]\tvalid_0's ndcg@5: 0.402678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:48:31,732] Trial 26 finished with value: 0.40270345985903505 and parameters: {'learning_rate': 0.04857825718604731, 'num_leaves': 74, 'min_child_samples': 34, 'reg_alpha': 0.00024315805246685464, 'reg_lambda': 0.013931286166211327}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[493]\tvalid_0's ndcg@5: 0.402703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.392281\n",
      "[200]\tvalid_0's ndcg@5: 0.39807\n",
      "[300]\tvalid_0's ndcg@5: 0.399579\n",
      "[400]\tvalid_0's ndcg@5: 0.40005\n",
      "[500]\tvalid_0's ndcg@5: 0.400827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:50:28,560] Trial 27 finished with value: 0.4012347874151322 and parameters: {'learning_rate': 0.06834306068366106, 'num_leaves': 88, 'min_child_samples': 47, 'reg_alpha': 0.003929761173523843, 'reg_lambda': 0.14036489833255963}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[484]\tvalid_0's ndcg@5: 0.401235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.383592\n",
      "[200]\tvalid_0's ndcg@5: 0.388443\n",
      "[300]\tvalid_0's ndcg@5: 0.391863\n",
      "[400]\tvalid_0's ndcg@5: 0.393852\n",
      "[500]\tvalid_0's ndcg@5: 0.396411\n",
      "[600]\tvalid_0's ndcg@5: 0.39738\n",
      "[700]\tvalid_0's ndcg@5: 0.398861\n",
      "[800]\tvalid_0's ndcg@5: 0.400073\n",
      "[900]\tvalid_0's ndcg@5: 0.400694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:55:48,698] Trial 28 finished with value: 0.40184864442504553 and parameters: {'learning_rate': 0.017052363412740197, 'num_leaves': 98, 'min_child_samples': 24, 'reg_alpha': 0.0004954193987243282, 'reg_lambda': 0.6532867831676925}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's ndcg@5: 0.401849\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's ndcg@5: 0.401849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[100]\tvalid_0's ndcg@5: 0.38303\n",
      "[200]\tvalid_0's ndcg@5: 0.387965\n",
      "[300]\tvalid_0's ndcg@5: 0.391606\n",
      "[400]\tvalid_0's ndcg@5: 0.393943\n",
      "[500]\tvalid_0's ndcg@5: 0.395791\n",
      "[600]\tvalid_0's ndcg@5: 0.397425\n",
      "[700]\tvalid_0's ndcg@5: 0.398565\n",
      "[800]\tvalid_0's ndcg@5: 0.399429\n",
      "[900]\tvalid_0's ndcg@5: 0.399464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 19:00:35,519] Trial 29 finished with value: 0.3999218177279299 and parameters: {'learning_rate': 0.022977417720309055, 'num_leaves': 62, 'min_child_samples': 40, 'reg_alpha': 0.0012959217136057817, 'reg_lambda': 0.04784958443914961}. Best is trial 15 with value: 0.4057677345356311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[863]\tvalid_0's ndcg@5: 0.399922\n",
      "Best trial:\n",
      "FrozenTrial(number=15, state=TrialState.COMPLETE, values=[0.4057677345356311], datetime_start=datetime.datetime(2025, 5, 12, 18, 19, 56, 560111), datetime_complete=datetime.datetime(2025, 5, 12, 18, 22, 29, 667330), params={'learning_rate': 0.03427673821049949, 'num_leaves': 79, 'min_child_samples': 50, 'reg_alpha': 0.0001416721648867782, 'reg_lambda': 0.12245976197134716}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.2, log=True, low=0.01, step=None), 'num_leaves': IntDistribution(high=100, log=False, low=10, step=1), 'min_child_samples': IntDistribution(high=50, log=False, low=10, step=1), 'reg_alpha': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=1.0, log=True, low=0.0001, step=None)}, trial_id=15, value=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.03427673821049949,\n",
       " 'num_leaves': 79,\n",
       " 'min_child_samples': 50,\n",
       " 'reg_alpha': 0.0001416721648867782,\n",
       " 'reg_lambda': 0.12245976197134716}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_ranker_model = LGBMRankerModel(train_df)\n",
    "feature_tester = FeatureTester(lgbm_ranker_model)\n",
    "X_train, y_train, X_val, y_val, groups_size_train, groups_size_val = lgbm_ranker_model.format_data(train_df)\n",
    "feature_tester.run_light_hpo(X_train, y_train, X_val, y_val, groups_size_train, groups_size_val, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fbb87f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.354891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5677\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 99\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.402751\n",
      "[750]\tvalid_0's ndcg@5: 0.404563\n",
      "Early stopping, best iteration is:\n",
      "[759]\tvalid_0's ndcg@5: 0.404779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2067\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 10\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.384514\n",
      "[500]\tvalid_0's ndcg@5: 0.38725\n",
      "[750]\tvalid_0's ndcg@5: 0.388952\n",
      "Early stopping, best iteration is:\n",
      "[866]\tvalid_0's ndcg@5: 0.389748\n",
      "Top 10 features: NDCG@5 = 0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3924\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 20\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.393207\n",
      "[500]\tvalid_0's ndcg@5: 0.399351\n",
      "[750]\tvalid_0's ndcg@5: 0.400871\n",
      "Early stopping, best iteration is:\n",
      "[703]\tvalid_0's ndcg@5: 0.401033\n",
      "Top 20 features: NDCG@5 = 0.4010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.169941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4530\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 30\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.396682\n",
      "[500]\tvalid_0's ndcg@5: 0.401275\n",
      "[750]\tvalid_0's ndcg@5: 0.403043\n",
      "Early stopping, best iteration is:\n",
      "[834]\tvalid_0's ndcg@5: 0.40329\n",
      "Top 30 features: NDCG@5 = 0.4033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.191530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5213\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 40\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397709\n",
      "[500]\tvalid_0's ndcg@5: 0.402738\n",
      "[750]\tvalid_0's ndcg@5: 0.404597\n",
      "Early stopping, best iteration is:\n",
      "[758]\tvalid_0's ndcg@5: 0.404652\n",
      "Top 40 features: NDCG@5 = 0.4047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.227008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5505\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 50\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.396975\n",
      "[500]\tvalid_0's ndcg@5: 0.401948\n",
      "[750]\tvalid_0's ndcg@5: 0.404328\n",
      "Early stopping, best iteration is:\n",
      "[775]\tvalid_0's ndcg@5: 0.404599\n",
      "Top 50 features: NDCG@5 = 0.4046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.321087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5574\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 60\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.402533\n",
      "[750]\tvalid_0's ndcg@5: 0.40503\n",
      "Early stopping, best iteration is:\n",
      "[870]\tvalid_0's ndcg@5: 0.405892\n",
      "Top 60 features: NDCG@5 = 0.4059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.351866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5600\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 70\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.40241\n",
      "[750]\tvalid_0's ndcg@5: 0.404411\n",
      "Early stopping, best iteration is:\n",
      "[786]\tvalid_0's ndcg@5: 0.404677\n",
      "Top 70 features: NDCG@5 = 0.4047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.322058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5631\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 80\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.402749\n",
      "[750]\tvalid_0's ndcg@5: 0.404562\n",
      "Early stopping, best iteration is:\n",
      "[847]\tvalid_0's ndcg@5: 0.404976\n",
      "Top 80 features: NDCG@5 = 0.4050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rik/.pyenv/versions/3.10.12/lib/python3.10/site-packages/lightgbm/sklearn.py:861: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.326132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5659\n",
      "[LightGBM] [Info] Number of data points in the train set: 3966677, number of used features: 90\n",
      "Training until validation scores don't improve for 80 rounds\n",
      "[250]\tvalid_0's ndcg@5: 0.397377\n",
      "[500]\tvalid_0's ndcg@5: 0.402749\n",
      "[750]\tvalid_0's ndcg@5: 0.404562\n",
      "Early stopping, best iteration is:\n",
      "[759]\tvalid_0's ndcg@5: 0.404787\n",
      "Top 90 features: NDCG@5 = 0.4048\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(\"data/training_set_processed.parquet\")\n",
    "lgbm_class_model = LGBMRankerModel(\n",
    "    df = train_df,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[5],\n",
    "    n_estimators=1000,\n",
    "    learning_rate= 0.03427673821049949,\n",
    "    num_leaves= 79,\n",
    "    min_child_samples=50,\n",
    "    reg_alpha= 0.0001416721648867782,\n",
    "    reg_lambda= 0.12245976197134716\n",
    ")\n",
    "feature_tester = FeatureTester(lgbm_class_model, \n",
    "                               categorical_features_threshold={\"site_id\": 5000, \"visitor_location_country_id\": 1000, \"prop_country_id\": 1000, \"srch_destination_id\": 5000},\n",
    "                               impute_null_columns={'prop_review_score': 'median', 'orig_destination_distance': 'mean'})\n",
    "results = feature_tester.full_feature_selection(train_df, feature_counts = list(range(10, 91, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed7764c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 0.38974781060330016),\n",
       " (20, 0.401032570169975),\n",
       " (30, 0.4032895258289042),\n",
       " (40, 0.4046517227639236),\n",
       " (50, 0.4045989239077548),\n",
       " (60, 0.4058918544565001),\n",
       " (70, 0.404677202480872),\n",
       " (80, 0.40497554088096377),\n",
       " (90, 0.4047873110376844)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
